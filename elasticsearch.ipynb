{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling large text collections with Elastic database\n",
    "=====================================================\n",
    "\n",
    "Estnltk has database module that simplifies working with large corpora.\n",
    "Check out wikipedia\\_tutorial, tei\\_tutorial for more information about\n",
    "getting started with larger text document collections.\n",
    "\n",
    "Estnltk database integrates with\n",
    "[Elastic](https://www.elastic.co/downloads/elasticsearch), which is a\n",
    "distributed RESTful schema-free JSON database, based on [Apache\n",
    "Lucene](https://lucene.apache.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing and we recommend use to docker and run elasticsearch with the command:\n",
    "\n",
    "    docker run --name estnltk_elastic -p 9200:9200 -d  elasticsearch:2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estnltk Elastic wrapper\n",
    "-----------------------\n",
    "\n",
    "To access estnltk elasticsearch wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk.database.elastic import *\n",
    "from estnltk.database.elastic.query_grammar import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = create_index('demo_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to connect to an existing index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = connect('demo_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify non-default arguments to elasticsearch connection, you can\n",
    "either pass the parameters to either method or create and Index instance\n",
    "manually, passing the Elastic python API client object as the first\n",
    "parameter.\n",
    "\n",
    "These methods return an index object that has two important methods:\n",
    "save and sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "t = Text('See on demolause. Sellele järgneb veel üks.')\n",
    "index.save(t)\n",
    "\n",
    "t = Text('Karu otsis talvekodu.')\n",
    "index.save(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#waiting for the sentences to be indexed\n",
    "import time\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['see', 'olema', 'demolause', '.']\n",
      "['see', 'järgnema', 'veel', 'üks', '.']\n",
      "['Karu', 'otsima', 'talvekodu', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in index.sentences():\n",
    "    print(sentence.lemmas) #note that the sentences generator returns estnltk Text objects by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the mapping and data structure in the elasticsearch index, refer\n",
    "to the mappings.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over corpora\n",
    "----------------------\n",
    "\n",
    "To iterate over the entire corpus use the Index.sentences generator. In\n",
    "the general case it is enough to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See on demolause.\n",
      "Sellele järgneb veel üks.\n",
      "Karu otsis talvekodu.\n"
     ]
    }
   ],
   "source": [
    "for sentence in index.sentences():\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over query results\n",
    "----------------------------\n",
    "\n",
    "To iterate over query results, pass the elasticsearch query to the\n",
    "sentences generator as the \"query\" parameter. The query should be a\n",
    "dictionary as expected by elasticsearch python API. It will be\n",
    "transformed into json before being transmitted.\n",
    "\n",
    "To simplify writing some queries, see the query\\_helper module. It\n",
    "defines the Word class that maps well to estnltk morphological analysis\n",
    "results. The general workflow is:\n",
    "\n",
    "1.  Define words to match with the Word class.\n",
    "2.  Combine them with boolean operators \"&\" and \"|\"\n",
    "3.  Wrap them in a Grammar object\n",
    "4.  Get the query via the Grammar.query() method.\n",
    "5.  Annotate the results with the Grammar.annotate() method that creates\n",
    "    a layer that marks the matching words.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karu otsis talvekodu.\n"
     ]
    }
   ],
   "source": [
    "grammar = Grammar(Word(lemma='otsima'))\n",
    "for sentence in index.sentences(query=grammar.query()):\n",
    "    #Optionally you can annotate the results against the grammar.\n",
    "    grammar.annotate(sentence, 'result')\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be visualised with the PrettyPrinter class or worked on\n",
    "using any other standard tools that work on estnltk layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger example\n",
    "\n",
    "We can load and analyze larger corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We'll create a database index from our estner corpus\n",
    "index = create_index('estner_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#and we'll insert all documents into the index\n",
    "for i in estnltk.corpus.yield_json_corpus('../../estnltk/corpora/estner.json'):\n",
    "    index.save(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Põhjus ise oli triviaalne ; seitsmeaastane poisslaps ronis omasuguste kambaga kuuri katusele , et sealt siis alla hüpata .\n",
      "\n",
      "Tema jaoks kehtib ikka veel teadmine , et kes kuurikatuselt alla ei hüppa , on memmekas .\n",
      "\n",
      "Juhid hindavad mõnikord oma oskusi üle .\n",
      "\n",
      "Samas on nende aasta 271 miljoni kroonine kasumiprognoos veidi üle pakutud , reaalsem oleks ehk 260 miljonit , \" lausus Hoiupanga börsimaakler Charlie Viikberg .\n",
      "\n",
      "Ta tõmbab kliendid üle , sest on parem võrk välja pakkuda , ” märgib Palts ja pakub välja , et Telial eesmärk on kas Eesti Telefon põhja lasta või vältida konkurentsi teket .\n",
      "\n",
      "Samas on nende aasta 271 miljoni kroonine kasumiprognoos veidi üle pakutud , reaalsem oleks ehk 260 miljonit , \" lausus Hoiupanga börsimaakler Charlie Viikberg .\n",
      "\n",
      "Ta tõmbab kliendid üle , sest on parem võrk välja pakkuda , ” märgib Palts ja pakub välja , et Telial eesmärk on kas Eesti Telefon põhja lasta või vältida konkurentsi teket .\n",
      "\n",
      "Juhid hindavad mõnikord oma oskusi üle .\n",
      "\n",
      "Juhid hindavad mõnikord oma oskusi üle .\n",
      "\n",
      "“ Proovireisija surm ” ( Nya Grupp 98 / Galeasen ) pakkus ehk kõige väljapeetumat esteetilist laadi - 90% osas säravvalge ja väga staatiline lavastus : nii näiteks istusid kõik osalised kogu tegevuse aja laval , poodiumidele asetatud toolidel ja tulid sealt siis oma episoodiks alla eeslavale .\n",
      "\n",
      "“ Kuigi Kolga nõustub , et Sami Lotila üldistused eestlaste kohta on üle pakutud , usub psühholoog , et teatud osas võivad need ka tõesed olla .\n",
      "\n",
      "“ Kuigi Kolga nõustub , et Sami Lotila üldistused eestlaste kohta on üle pakutud , usub psühholoog , et teatud osas võivad need ka tõesed olla .\n",
      "\n",
      "“ Proovireisija surm ” ( Nya Grupp 98 / Galeasen ) pakkus ehk kõige väljapeetumat esteetilist laadi - 90% osas säravvalge ja väga staatiline lavastus : nii näiteks istusid kõik osalised kogu tegevuse aja laval , poodiumidele asetatud toolidel ja tulid sealt siis oma episoodiks alla eeslavale .\n",
      "\n",
      "Põhjus ise oli triviaalne ; seitsmeaastane poisslaps ronis omasuguste kambaga kuuri katusele , et sealt siis alla hüpata .\n",
      "\n",
      "Tema jaoks kehtib ikka veel teadmine , et kes kuurikatuselt alla ei hüppa , on memmekas .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We'd like to search for sentences that contain some specific adverbs and some specific verbs\n",
    "grammar = Grammar(\n",
    "    Word(\n",
    "            partofspeech = ['D'], #adverb - määrsõna\n",
    "            lemma=['üle', 'alla'] \n",
    "        ) & Word(\n",
    "            partofspeech = 'V', #verb\n",
    "            lemma=['hüppama', 'hindama', 'pakkuma'] \n",
    "    )\n",
    ")\n",
    "\n",
    "for sentence in index.sentences(query=grammar.query()):\n",
    "    grammar.annotate(sentence, 'result')\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes\n",
    "\n",
    "It is important to note that these types of requests take full advantage of elasticsearch indices and are completed practically instantly."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
