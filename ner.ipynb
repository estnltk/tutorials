{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named entity recognition\n",
    "========================\n",
    "\n",
    "Named-entity recognition (NER) (also known as entity identification,\n",
    "entity chunking and entity extraction) is a subtask of information\n",
    "extraction that seeks to locate and classify elements in text into\n",
    "pre-defined categories such as the names of persons, organizations,\n",
    "locations.\n",
    "\n",
    "In this tutorial you will learn how to use estnltk's out of the box NER\n",
    "utilities and how to build your own ner-models from scratch.\n",
    "\n",
    "Getting started with NER\n",
    "------------------------\n",
    "\n",
    "The estnltk package comes with the pre-trained NER-models for Python\n",
    "2.7/Python 3.4. The models distinguish 3 types of entities: person\n",
    "names, organizations and locations.\n",
    "\n",
    "A quick example below demonstrates how to extract named entities from\n",
    "the raw text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eesti vabariik',\n",
      " 'Põhja-Euroobas|Põhja-Euroopa',\n",
      " 'Eesti',\n",
      " 'Soome laht',\n",
      " 'Soome Vabariik',\n",
      " 'Riigikogu',\n",
      " 'Eesti vabariik',\n",
      " 'riigikogu',\n",
      " 'Eesti',\n",
      " 'Andrus Ansip',\n",
      " 'Toomas Hendrik Ilves']\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from pprint import pprint\n",
    "\n",
    "text = Text('''Eesti Vabariik on riik Põhja-Euroopas. \n",
    "    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\n",
    "    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\n",
    "    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\n",
    "    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\n",
    "    ''')\n",
    "\n",
    "# Extract named entities\n",
    "pprint(text.named_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When accessing the property **named\\_entities** of\n",
    "the **Text** instance, estnltk executes on the background\n",
    "the whole text processing pipeline, including tokenization,\n",
    "morphological analysis and named entity extraction.\n",
    "\n",
    "The class **Text** additionally provides a number of useful\n",
    "methods to get more information on the extracted entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Eesti vabariik', 'LOC', (0, 14)),\n",
      " ('Põhja-Euroobas|Põhja-Euroopa', 'LOC', (23, 37)),\n",
      " ('Eesti', 'LOC', (44, 49)),\n",
      " ('Soome laht', 'LOC', (69, 79)),\n",
      " ('Soome Vabariik', 'LOC', (80, 97)),\n",
      " ('Riigikogu', 'ORG', (103, 112)),\n",
      " ('Eesti vabariik', 'LOC', (116, 131)),\n",
      " ('riigikogu', 'ORG', (143, 154)),\n",
      " ('Eesti', 'LOC', (162, 168)),\n",
      " ('Andrus Ansip', 'PER', (223, 235)),\n",
      " ('Toomas Hendrik Ilves', 'PER', (312, 332))]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(zip(text.named_entities, text.named_entity_labels, text.named_entity_spans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default models use tags PER, ORG and LOC to denote person names,\n",
    "organizations and locations respectively. Entity tags are encoded using\n",
    "a BIO annotation scheme, where each entity label is prefixed with either\n",
    "B or I letter. B- denotes the beginning and I- inside of an entity. The\n",
    "prefixes are used to detect multiword entities, as shown in the example\n",
    "example above. All other words, which don't refer to entities of\n",
    "interest, are labelled with the O tag.\n",
    "\n",
    "The raw labels are accessible via the property\n",
    "**labels** of the **Text** instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Eesti', 'B-LOC'),\n",
      " ('Vabariik', 'I-LOC'),\n",
      " ('on', 'O'),\n",
      " ('riik', 'O'),\n",
      " ('Põhja-Euroopas', 'B-LOC'),\n",
      " ('.', 'O'),\n",
      " ('Eesti', 'B-LOC'),\n",
      " ('piirneb', 'O'),\n",
      " ('põhjas', 'O'),\n",
      " ('üle', 'O'),\n",
      " ('Soome', 'B-LOC'),\n",
      " ('lahe', 'I-LOC'),\n",
      " ('Soome', 'B-LOC'),\n",
      " ('Vabariigiga', 'I-LOC'),\n",
      " ('.', 'O'),\n",
      " ('Riigikogu', 'B-ORG'),\n",
      " ('on', 'O'),\n",
      " ('Eesti', 'B-LOC'),\n",
      " ('Vabariigi', 'I-LOC'),\n",
      " ('parlament', 'O'),\n",
      " ('.', 'O'),\n",
      " ('Riigikogule', 'B-ORG'),\n",
      " ('kuulub', 'O'),\n",
      " ('Eestis', 'B-LOC'),\n",
      " ('seadusandlik', 'O'),\n",
      " ('võim', 'O'),\n",
      " ('.', 'O'),\n",
      " ('2005.', 'O'),\n",
      " ('aastal', 'O'),\n",
      " ('sai', 'O'),\n",
      " ('peaministriks', 'O'),\n",
      " ('Andrus', 'B-PER'),\n",
      " ('Ansip', 'I-PER'),\n",
      " (',', 'O'),\n",
      " ('kes', 'O'),\n",
      " ('püsis', 'O'),\n",
      " ('sellel', 'O'),\n",
      " ('kohal', 'O'),\n",
      " ('2014.', 'O'),\n",
      " ('aastani', 'O'),\n",
      " ('.', 'O'),\n",
      " ('2006.', 'O'),\n",
      " ('aastal', 'O'),\n",
      " ('valiti', 'O'),\n",
      " ('presidendiks', 'O'),\n",
      " ('Toomas', 'B-PER'),\n",
      " ('Hendrik', 'I-PER'),\n",
      " ('Ilves', 'I-PER'),\n",
      " ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(zip(text.word_texts, text.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced NER\n",
    "------------\n",
    "\n",
    "### Training custom models\n",
    "\n",
    "Default models that come with estnltk are good enough for basic tasks.\n",
    "However, for some specific tasks, a custom NER model might be needed. To\n",
    "train your own model, you need to provide a training corpus and custom\n",
    "configuration settings. The following example demonstrates how to train\n",
    "a ner-model using the default training dataset and settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 27502\n",
      "Seconds required: 6.768\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 1000\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 31638.553113\n",
      "Trial #1 (eta = 0.100000): 35731.461497 (worse)\n",
      "Trial #2 (eta = 0.050000): 18483.224381\n",
      "Trial #3 (eta = 0.025000): 8702.151411\n",
      "Trial #4 (eta = 0.012500): 4843.039483\n",
      "Trial #5 (eta = 0.006250): 3396.892994\n",
      "Trial #6 (eta = 0.003125): 3447.987218\n",
      "Trial #7 (eta = 0.001563): 3931.664338\n",
      "Trial #8 (eta = 0.000781): 4644.600628\n",
      "Trial #9 (eta = 0.000391): 5567.995675\n",
      "Trial #10 (eta = 0.000195): 6670.063105\n",
      "Trial #11 (eta = 0.000098): 7850.731749\n",
      "Best learning rate (eta): 0.006250\n",
      "Seconds required: 1.854\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 24172.323175\n",
      "Feature L2-norm: 11.489745\n",
      "Learning rate (eta): 0.006250\n",
      "Total number of feature updates: 13627\n",
      "Seconds required for this iteration: 2.242\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 17437.850172\n",
      "Feature L2-norm: 14.999275\n",
      "Learning rate (eta): 0.006250\n",
      "Total number of feature updates: 27254\n",
      "Seconds required for this iteration: 2.634\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 14603.051437\n",
      "Feature L2-norm: 17.279376\n",
      "Learning rate (eta): 0.006250\n",
      "Total number of feature updates: 40881\n",
      "Seconds required for this iteration: 2.450\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 13176.361125\n",
      "Feature L2-norm: 19.118737\n",
      "Learning rate (eta): 0.006250\n",
      "Total number of feature updates: 54508\n",
      "Seconds required for this iteration: 3.042\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 12730.723482\n",
      "Feature L2-norm: 20.790962\n",
      "Learning rate (eta): 0.006250\n",
      "Total number of feature updates: 68135\n",
      "Seconds required for this iteration: 2.573\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 11931.002309\n",
      "Feature L2-norm: 22.228954\n",
      "Learning rate (eta): 0.006250\n",
      "Total number of feature updates: 81762\n",
      "Seconds required for this iteration: 2.524\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 11423.056976\n",
      "Feature L2-norm: 23.490672\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 95389\n",
      "Seconds required for this iteration: 2.386\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 10828.498775\n",
      "Feature L2-norm: 24.708994\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 109016\n",
      "Seconds required for this iteration: 2.287\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 10788.422810\n",
      "Feature L2-norm: 25.829739\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 122643\n",
      "Seconds required for this iteration: 2.314\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 10438.570465\n",
      "Feature L2-norm: 26.938894\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 136270\n",
      "Seconds required for this iteration: 2.281\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 10043.065386\n",
      "Improvement ratio: 1.406867\n",
      "Feature L2-norm: 27.925413\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 149897\n",
      "Seconds required for this iteration: 2.237\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 9770.657559\n",
      "Improvement ratio: 0.784716\n",
      "Feature L2-norm: 28.854242\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 163524\n",
      "Seconds required for this iteration: 2.332\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 9519.320418\n",
      "Improvement ratio: 0.534043\n",
      "Feature L2-norm: 29.784878\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 177151\n",
      "Seconds required for this iteration: 2.260\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 9353.606100\n",
      "Improvement ratio: 0.408693\n",
      "Feature L2-norm: 30.665230\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 190778\n",
      "Seconds required for this iteration: 2.228\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 9296.988569\n",
      "Improvement ratio: 0.369338\n",
      "Feature L2-norm: 31.547644\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 204405\n",
      "Seconds required for this iteration: 2.248\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 8977.041074\n",
      "Improvement ratio: 0.329057\n",
      "Feature L2-norm: 32.310120\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 218032\n",
      "Seconds required for this iteration: 2.384\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 8753.414586\n",
      "Improvement ratio: 0.304983\n",
      "Feature L2-norm: 33.077887\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 231659\n",
      "Seconds required for this iteration: 2.260\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 8615.470943\n",
      "Improvement ratio: 0.256867\n",
      "Feature L2-norm: 33.819993\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 245286\n",
      "Seconds required for this iteration: 2.369\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 8647.210640\n",
      "Improvement ratio: 0.247619\n",
      "Feature L2-norm: 34.548685\n",
      "Learning rate (eta): 0.006249\n",
      "Total number of feature updates: 258913\n",
      "Seconds required for this iteration: 2.285\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 8415.766213\n",
      "Improvement ratio: 0.240359\n",
      "Feature L2-norm: 35.239045\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 272540\n",
      "Seconds required for this iteration: 2.208\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 8352.817726\n",
      "Improvement ratio: 0.202357\n",
      "Feature L2-norm: 35.923932\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 286167\n",
      "Seconds required for this iteration: 2.215\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 8012.951016\n",
      "Improvement ratio: 0.219358\n",
      "Feature L2-norm: 36.593067\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 299794\n",
      "Seconds required for this iteration: 2.227\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 8003.668161\n",
      "Improvement ratio: 0.189370\n",
      "Feature L2-norm: 37.232795\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 313421\n",
      "Seconds required for this iteration: 2.284\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 7971.556406\n",
      "Improvement ratio: 0.173373\n",
      "Feature L2-norm: 37.851651\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 327048\n",
      "Seconds required for this iteration: 2.314\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 7858.109927\n",
      "Improvement ratio: 0.183107\n",
      "Feature L2-norm: 38.474759\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 340675\n",
      "Seconds required for this iteration: 2.233\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 7826.285303\n",
      "Improvement ratio: 0.147037\n",
      "Feature L2-norm: 39.084558\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 354302\n",
      "Seconds required for this iteration: 2.228\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 7561.982039\n",
      "Improvement ratio: 0.157556\n",
      "Feature L2-norm: 39.662134\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 367929\n",
      "Seconds required for this iteration: 2.307\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 7533.611135\n",
      "Improvement ratio: 0.143604\n",
      "Feature L2-norm: 40.243017\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 381556\n",
      "Seconds required for this iteration: 2.323\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 7572.395636\n",
      "Improvement ratio: 0.141939\n",
      "Feature L2-norm: 40.804884\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 395183\n",
      "Seconds required for this iteration: 2.577\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 7760.523813\n",
      "Improvement ratio: 0.084433\n",
      "Feature L2-norm: 41.402348\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 408810\n",
      "Seconds required for this iteration: 2.340\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 7325.448007\n",
      "Improvement ratio: 0.140247\n",
      "Feature L2-norm: 41.936366\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 422437\n",
      "Seconds required for this iteration: 2.220\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 7293.024122\n",
      "Improvement ratio: 0.098714\n",
      "Feature L2-norm: 42.438341\n",
      "Learning rate (eta): 0.006248\n",
      "Total number of feature updates: 436064\n",
      "Seconds required for this iteration: 2.221\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 7244.779177\n",
      "Improvement ratio: 0.104750\n",
      "Feature L2-norm: 42.976112\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 449691\n",
      "Seconds required for this iteration: 2.214\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 7242.763835\n",
      "Improvement ratio: 0.100624\n",
      "Feature L2-norm: 43.494941\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 463318\n",
      "Seconds required for this iteration: 2.209\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 7116.230765\n",
      "Improvement ratio: 0.104252\n",
      "Feature L2-norm: 43.986289\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 476945\n",
      "Seconds required for this iteration: 2.207\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 6926.261111\n",
      "Improvement ratio: 0.129944\n",
      "Feature L2-norm: 44.456970\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 490572\n",
      "Seconds required for this iteration: 2.212\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 6737.924857\n",
      "Improvement ratio: 0.122301\n",
      "Feature L2-norm: 44.917716\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 504199\n",
      "Seconds required for this iteration: 2.212\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 6849.786019\n",
      "Improvement ratio: 0.099832\n",
      "Feature L2-norm: 45.409762\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 517826\n",
      "Seconds required for this iteration: 2.213\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 6792.568097\n",
      "Improvement ratio: 0.114806\n",
      "Feature L2-norm: 45.879099\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 531453\n",
      "Seconds required for this iteration: 2.211\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 6780.774555\n",
      "Improvement ratio: 0.144489\n",
      "Feature L2-norm: 46.343984\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 545080\n",
      "Seconds required for this iteration: 2.207\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 6687.597819\n",
      "Improvement ratio: 0.095378\n",
      "Feature L2-norm: 46.810985\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 558707\n",
      "Seconds required for this iteration: 2.247\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 6536.067468\n",
      "Improvement ratio: 0.115812\n",
      "Feature L2-norm: 47.258200\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 572334\n",
      "Seconds required for this iteration: 2.339\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 6581.846926\n",
      "Improvement ratio: 0.100721\n",
      "Feature L2-norm: 47.695587\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 585961\n",
      "Seconds required for this iteration: 2.544\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 6599.960328\n",
      "Improvement ratio: 0.097395\n",
      "Feature L2-norm: 48.124905\n",
      "Learning rate (eta): 0.006247\n",
      "Total number of feature updates: 599588\n",
      "Seconds required for this iteration: 2.475\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 6294.837676\n",
      "Improvement ratio: 0.130487\n",
      "Feature L2-norm: 48.534130\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 613215\n",
      "Seconds required for this iteration: 2.705\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 6297.926053\n",
      "Improvement ratio: 0.099769\n",
      "Feature L2-norm: 48.958298\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 626842\n",
      "Seconds required for this iteration: 2.660\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 6429.674431\n",
      "Improvement ratio: 0.047942\n",
      "Feature L2-norm: 49.377750\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 640469\n",
      "Seconds required for this iteration: 2.430\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 6344.073383\n",
      "Improvement ratio: 0.079714\n",
      "Feature L2-norm: 49.793494\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 654096\n",
      "Seconds required for this iteration: 2.542\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 6251.740036\n",
      "Improvement ratio: 0.086508\n",
      "Feature L2-norm: 50.191270\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 667723\n",
      "Seconds required for this iteration: 2.643\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 6452.066472\n",
      "Improvement ratio: 0.050946\n",
      "Feature L2-norm: 50.633720\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 681350\n",
      "Seconds required for this iteration: 2.461\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 6228.274340\n",
      "Improvement ratio: 0.073748\n",
      "Feature L2-norm: 51.022656\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 694977\n",
      "Seconds required for this iteration: 2.212\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 6062.460396\n",
      "Improvement ratio: 0.078121\n",
      "Feature L2-norm: 51.402333\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 708604\n",
      "Seconds required for this iteration: 2.228\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 6117.835141\n",
      "Improvement ratio: 0.075846\n",
      "Feature L2-norm: 51.798198\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 722231\n",
      "Seconds required for this iteration: 2.419\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 6107.244204\n",
      "Improvement ratio: 0.080677\n",
      "Feature L2-norm: 52.192626\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 735858\n",
      "Seconds required for this iteration: 2.483\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 5985.627415\n",
      "Improvement ratio: 0.051659\n",
      "Feature L2-norm: 52.561419\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 749485\n",
      "Seconds required for this iteration: 2.415\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 5888.322088\n",
      "Improvement ratio: 0.069562\n",
      "Feature L2-norm: 52.912556\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 763112\n",
      "Seconds required for this iteration: 2.735\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 5951.860407\n",
      "Improvement ratio: 0.080280\n",
      "Feature L2-norm: 53.297624\n",
      "Learning rate (eta): 0.006246\n",
      "Total number of feature updates: 776739\n",
      "Seconds required for this iteration: 2.751\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 6006.490059\n",
      "Improvement ratio: 0.056203\n",
      "Feature L2-norm: 53.674991\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 790366\n",
      "Seconds required for this iteration: 2.877\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 5849.553564\n",
      "Improvement ratio: 0.068755\n",
      "Feature L2-norm: 54.031660\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 803993\n",
      "Seconds required for this iteration: 2.747\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 5875.815262\n",
      "Improvement ratio: 0.098072\n",
      "Feature L2-norm: 54.398836\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 817620\n",
      "Seconds required for this iteration: 2.269\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 5747.739373\n",
      "Improvement ratio: 0.083604\n",
      "Feature L2-norm: 54.750072\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 831247\n",
      "Seconds required for this iteration: 2.222\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 5763.525957\n",
      "Improvement ratio: 0.051867\n",
      "Feature L2-norm: 55.101784\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 844874\n",
      "Seconds required for this iteration: 2.245\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 5859.015977\n",
      "Improvement ratio: 0.044175\n",
      "Feature L2-norm: 55.452638\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 858501\n",
      "Seconds required for this iteration: 2.442\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 5642.765716\n",
      "Improvement ratio: 0.082314\n",
      "Feature L2-norm: 55.792717\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 872128\n",
      "Seconds required for this iteration: 2.637\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 5733.884922\n",
      "Improvement ratio: 0.043904\n",
      "Feature L2-norm: 56.140350\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 885755\n",
      "Seconds required for this iteration: 2.308\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 5631.802570\n",
      "Improvement ratio: 0.045548\n",
      "Feature L2-norm: 56.465068\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 899382\n",
      "Seconds required for this iteration: 2.252\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 5642.788044\n",
      "Improvement ratio: 0.054773\n",
      "Feature L2-norm: 56.810243\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 913009\n",
      "Seconds required for this iteration: 2.225\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 5557.149716\n",
      "Improvement ratio: 0.080858\n",
      "Feature L2-norm: 57.131408\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 926636\n",
      "Seconds required for this iteration: 2.219\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 5563.991204\n",
      "Improvement ratio: 0.051323\n",
      "Feature L2-norm: 57.463177\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 940263\n",
      "Seconds required for this iteration: 2.216\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 5534.039170\n",
      "Improvement ratio: 0.061759\n",
      "Feature L2-norm: 57.779475\n",
      "Learning rate (eta): 0.006245\n",
      "Total number of feature updates: 953890\n",
      "Seconds required for this iteration: 2.301\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 5511.189692\n",
      "Improvement ratio: 0.042922\n",
      "Feature L2-norm: 58.100620\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 967517\n",
      "Seconds required for this iteration: 2.223\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 5521.831739\n",
      "Improvement ratio: 0.043771\n",
      "Feature L2-norm: 58.429066\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 981144\n",
      "Seconds required for this iteration: 2.236\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 5547.368054\n",
      "Improvement ratio: 0.056179\n",
      "Feature L2-norm: 58.738911\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 994771\n",
      "Seconds required for this iteration: 2.218\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 5413.542636\n",
      "Improvement ratio: 0.042343\n",
      "Feature L2-norm: 59.066447\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1008398\n",
      "Seconds required for this iteration: 2.282\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 5479.117009\n",
      "Improvement ratio: 0.046498\n",
      "Feature L2-norm: 59.379124\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1022025\n",
      "Seconds required for this iteration: 2.248\n",
      "\n",
      "***** Epoch #76 *****\n",
      "Loss: 5364.784325\n",
      "Improvement ratio: 0.049772\n",
      "Feature L2-norm: 59.678795\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1035652\n",
      "Seconds required for this iteration: 2.233\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 5390.763873\n",
      "Improvement ratio: 0.046751\n",
      "Feature L2-norm: 59.987214\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1049279\n",
      "Seconds required for this iteration: 2.208\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 5278.013108\n",
      "Improvement ratio: 0.052887\n",
      "Feature L2-norm: 60.286602\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1062906\n",
      "Seconds required for this iteration: 2.234\n",
      "\n",
      "***** Epoch #79 *****\n",
      "Loss: 5503.584990\n",
      "Improvement ratio: 0.010976\n",
      "Feature L2-norm: 60.615750\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1076533\n",
      "Seconds required for this iteration: 2.255\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 5252.502895\n",
      "Improvement ratio: 0.053600\n",
      "Feature L2-norm: 60.905667\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1090160\n",
      "Seconds required for this iteration: 2.247\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 5208.782001\n",
      "Improvement ratio: 0.058057\n",
      "Feature L2-norm: 61.188753\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1103787\n",
      "Seconds required for this iteration: 2.265\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 5301.925370\n",
      "Improvement ratio: 0.041477\n",
      "Feature L2-norm: 61.480326\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1117414\n",
      "Seconds required for this iteration: 2.330\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 5240.890727\n",
      "Improvement ratio: 0.058478\n",
      "Feature L2-norm: 61.783081\n",
      "Learning rate (eta): 0.006244\n",
      "Total number of feature updates: 1131041\n",
      "Seconds required for this iteration: 2.268\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 5166.391532\n",
      "Improvement ratio: 0.047838\n",
      "Feature L2-norm: 62.065784\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1144668\n",
      "Seconds required for this iteration: 2.238\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 5210.295613\n",
      "Improvement ratio: 0.051594\n",
      "Feature L2-norm: 62.348039\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1158295\n",
      "Seconds required for this iteration: 2.310\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 5126.991931\n",
      "Improvement ratio: 0.046380\n",
      "Feature L2-norm: 62.635585\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1171922\n",
      "Seconds required for this iteration: 2.530\n",
      "\n",
      "***** Epoch #87 *****\n",
      "Loss: 5141.276434\n",
      "Improvement ratio: 0.048526\n",
      "Feature L2-norm: 62.911186\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1185549\n",
      "Seconds required for this iteration: 2.405\n",
      "\n",
      "***** Epoch #88 *****\n",
      "Loss: 5066.095799\n",
      "Improvement ratio: 0.041830\n",
      "Feature L2-norm: 63.180545\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1199176\n",
      "Seconds required for this iteration: 2.214\n",
      "\n",
      "***** Epoch #89 *****\n",
      "Loss: 5166.625987\n",
      "Improvement ratio: 0.065218\n",
      "Feature L2-norm: 63.475972\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1212803\n",
      "Seconds required for this iteration: 2.328\n",
      "\n",
      "***** Epoch #90 *****\n",
      "Loss: 5060.271510\n",
      "Improvement ratio: 0.037988\n",
      "Feature L2-norm: 63.759460\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1226430\n",
      "Seconds required for this iteration: 2.207\n",
      "\n",
      "***** Epoch #91 *****\n",
      "Loss: 4964.187813\n",
      "Improvement ratio: 0.049272\n",
      "Feature L2-norm: 64.031666\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1240057\n",
      "Seconds required for this iteration: 2.215\n",
      "\n",
      "***** Epoch #92 *****\n",
      "Loss: 5009.853158\n",
      "Improvement ratio: 0.058300\n",
      "Feature L2-norm: 64.293819\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1253684\n",
      "Seconds required for this iteration: 2.233\n",
      "\n",
      "***** Epoch #93 *****\n",
      "Loss: 4968.178641\n",
      "Improvement ratio: 0.054892\n",
      "Feature L2-norm: 64.569636\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1267311\n",
      "Seconds required for this iteration: 2.319\n",
      "\n",
      "***** Epoch #94 *****\n",
      "Loss: 5047.727315\n",
      "Improvement ratio: 0.023508\n",
      "Feature L2-norm: 64.848972\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1280938\n",
      "Seconds required for this iteration: 2.248\n",
      "\n",
      "***** Epoch #95 *****\n",
      "Loss: 4891.409892\n",
      "Improvement ratio: 0.065193\n",
      "Feature L2-norm: 65.108829\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1294565\n",
      "Seconds required for this iteration: 2.238\n",
      "\n",
      "***** Epoch #96 *****\n",
      "Loss: 4985.682275\n",
      "Improvement ratio: 0.028343\n",
      "Feature L2-norm: 65.391411\n",
      "Learning rate (eta): 0.006243\n",
      "Total number of feature updates: 1308192\n",
      "Seconds required for this iteration: 2.230\n",
      "\n",
      "***** Epoch #97 *****\n",
      "Loss: 5114.622015\n",
      "Improvement ratio: 0.005211\n",
      "Feature L2-norm: 65.668532\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1321819\n",
      "Seconds required for this iteration: 2.233\n",
      "\n",
      "***** Epoch #98 *****\n",
      "Loss: 4868.592901\n",
      "Improvement ratio: 0.040567\n",
      "Feature L2-norm: 65.933151\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1335446\n",
      "Seconds required for this iteration: 2.246\n",
      "\n",
      "***** Epoch #99 *****\n",
      "Loss: 4844.773246\n",
      "Improvement ratio: 0.066433\n",
      "Feature L2-norm: 66.186809\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1349073\n",
      "Seconds required for this iteration: 2.229\n",
      "\n",
      "***** Epoch #100 *****\n",
      "Loss: 4921.709631\n",
      "Improvement ratio: 0.028153\n",
      "Feature L2-norm: 66.453857\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1362700\n",
      "Seconds required for this iteration: 2.231\n",
      "\n",
      "***** Epoch #101 *****\n",
      "Loss: 4789.900702\n",
      "Improvement ratio: 0.036386\n",
      "Feature L2-norm: 66.716848\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1376327\n",
      "Seconds required for this iteration: 2.215\n",
      "\n",
      "***** Epoch #102 *****\n",
      "Loss: 4788.309280\n",
      "Improvement ratio: 0.046268\n",
      "Feature L2-norm: 66.976715\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1389954\n",
      "Seconds required for this iteration: 2.228\n",
      "\n",
      "***** Epoch #103 *****\n",
      "Loss: 4795.595050\n",
      "Improvement ratio: 0.035988\n",
      "Feature L2-norm: 67.231667\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1403581\n",
      "Seconds required for this iteration: 2.220\n",
      "\n",
      "***** Epoch #104 *****\n",
      "Loss: 4896.397755\n",
      "Improvement ratio: 0.030906\n",
      "Feature L2-norm: 67.490533\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1417208\n",
      "Seconds required for this iteration: 2.233\n",
      "\n",
      "***** Epoch #105 *****\n",
      "Loss: 4706.124091\n",
      "Improvement ratio: 0.039371\n",
      "Feature L2-norm: 67.737461\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1430835\n",
      "Seconds required for this iteration: 2.220\n",
      "\n",
      "***** Epoch #106 *****\n",
      "Loss: 4753.854731\n",
      "Improvement ratio: 0.048766\n",
      "Feature L2-norm: 67.983183\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1444462\n",
      "Seconds required for this iteration: 2.318\n",
      "\n",
      "***** Epoch #107 *****\n",
      "Loss: 4835.783535\n",
      "Improvement ratio: 0.057661\n",
      "Feature L2-norm: 68.237816\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1458089\n",
      "Seconds required for this iteration: 2.326\n",
      "\n",
      "***** Epoch #108 *****\n",
      "Loss: 4708.315868\n",
      "Improvement ratio: 0.034041\n",
      "Feature L2-norm: 68.490847\n",
      "Learning rate (eta): 0.006242\n",
      "Total number of feature updates: 1471716\n",
      "Seconds required for this iteration: 2.275\n",
      "\n",
      "***** Epoch #109 *****\n",
      "Loss: 4714.363397\n",
      "Improvement ratio: 0.027662\n",
      "Feature L2-norm: 68.741470\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1485343\n",
      "Seconds required for this iteration: 2.285\n",
      "\n",
      "***** Epoch #110 *****\n",
      "Loss: 4764.498215\n",
      "Improvement ratio: 0.032996\n",
      "Feature L2-norm: 68.989531\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1498970\n",
      "Seconds required for this iteration: 2.313\n",
      "\n",
      "***** Epoch #111 *****\n",
      "Loss: 4702.949558\n",
      "Improvement ratio: 0.018489\n",
      "Feature L2-norm: 69.228922\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1512597\n",
      "Seconds required for this iteration: 2.261\n",
      "\n",
      "***** Epoch #112 *****\n",
      "Loss: 4681.255269\n",
      "Improvement ratio: 0.022869\n",
      "Feature L2-norm: 69.473358\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1526224\n",
      "Seconds required for this iteration: 2.251\n",
      "\n",
      "***** Epoch #113 *****\n",
      "Loss: 4722.102327\n",
      "Improvement ratio: 0.015564\n",
      "Feature L2-norm: 69.720548\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1539851\n",
      "Seconds required for this iteration: 2.384\n",
      "\n",
      "***** Epoch #114 *****\n",
      "Loss: 4585.640466\n",
      "Improvement ratio: 0.067767\n",
      "Feature L2-norm: 69.951587\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1553478\n",
      "Seconds required for this iteration: 2.286\n",
      "\n",
      "***** Epoch #115 *****\n",
      "Loss: 4664.131282\n",
      "Improvement ratio: 0.009003\n",
      "Feature L2-norm: 70.190197\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1567105\n",
      "Seconds required for this iteration: 2.235\n",
      "\n",
      "***** Epoch #116 *****\n",
      "Loss: 4613.366616\n",
      "Improvement ratio: 0.030452\n",
      "Feature L2-norm: 70.425920\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1580732\n",
      "Seconds required for this iteration: 2.227\n",
      "\n",
      "***** Epoch #117 *****\n",
      "Loss: 4614.199853\n",
      "Improvement ratio: 0.048022\n",
      "Feature L2-norm: 70.668697\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1594359\n",
      "Seconds required for this iteration: 2.211\n",
      "\n",
      "***** Epoch #118 *****\n",
      "Loss: 4609.819200\n",
      "Improvement ratio: 0.021367\n",
      "Feature L2-norm: 70.902847\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1607986\n",
      "Seconds required for this iteration: 2.504\n",
      "\n",
      "***** Epoch #119 *****\n",
      "Loss: 4544.535893\n",
      "Improvement ratio: 0.037370\n",
      "Feature L2-norm: 71.130045\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1621613\n",
      "Seconds required for this iteration: 2.398\n",
      "\n",
      "***** Epoch #120 *****\n",
      "Loss: 4635.104857\n",
      "Improvement ratio: 0.027916\n",
      "Feature L2-norm: 71.375496\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1635240\n",
      "Seconds required for this iteration: 2.811\n",
      "\n",
      "***** Epoch #121 *****\n",
      "Loss: 4530.647645\n",
      "Improvement ratio: 0.038030\n",
      "Feature L2-norm: 71.605246\n",
      "Learning rate (eta): 0.006241\n",
      "Total number of feature updates: 1648867\n",
      "Seconds required for this iteration: 2.707\n",
      "\n",
      "***** Epoch #122 *****\n",
      "Loss: 4541.986987\n",
      "Improvement ratio: 0.030662\n",
      "Feature L2-norm: 71.837709\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1662494\n",
      "Seconds required for this iteration: 2.500\n",
      "\n",
      "***** Epoch #123 *****\n",
      "Loss: 4479.125406\n",
      "Improvement ratio: 0.054247\n",
      "Feature L2-norm: 72.068895\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1676121\n",
      "Seconds required for this iteration: 2.785\n",
      "\n",
      "***** Epoch #124 *****\n",
      "Loss: 4459.762067\n",
      "Improvement ratio: 0.028225\n",
      "Feature L2-norm: 72.295359\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1689748\n",
      "Seconds required for this iteration: 2.540\n",
      "\n",
      "***** Epoch #125 *****\n",
      "Loss: 4433.583594\n",
      "Improvement ratio: 0.052000\n",
      "Feature L2-norm: 72.518676\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1703375\n",
      "Seconds required for this iteration: 2.210\n",
      "\n",
      "***** Epoch #126 *****\n",
      "Loss: 4448.369673\n",
      "Improvement ratio: 0.037092\n",
      "Feature L2-norm: 72.748678\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1717002\n",
      "Seconds required for this iteration: 2.221\n",
      "\n",
      "***** Epoch #127 *****\n",
      "Loss: 4434.348927\n",
      "Improvement ratio: 0.040559\n",
      "Feature L2-norm: 72.965152\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1730629\n",
      "Seconds required for this iteration: 2.494\n",
      "\n",
      "***** Epoch #128 *****\n",
      "Loss: 4434.377590\n",
      "Improvement ratio: 0.039564\n",
      "Feature L2-norm: 73.191414\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1744256\n",
      "Seconds required for this iteration: 2.510\n",
      "\n",
      "***** Epoch #129 *****\n",
      "Loss: 4528.904989\n",
      "Improvement ratio: 0.003451\n",
      "Feature L2-norm: 73.423359\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1757883\n",
      "Seconds required for this iteration: 2.435\n",
      "\n",
      "***** Epoch #130 *****\n",
      "Loss: 4317.636528\n",
      "Improvement ratio: 0.073528\n",
      "Feature L2-norm: 73.640535\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1771510\n",
      "Seconds required for this iteration: 2.337\n",
      "\n",
      "***** Epoch #131 *****\n",
      "Loss: 4441.530100\n",
      "Improvement ratio: 0.020065\n",
      "Feature L2-norm: 73.862459\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1785137\n",
      "Seconds required for this iteration: 2.347\n",
      "\n",
      "***** Epoch #132 *****\n",
      "Loss: 4544.574722\n",
      "Improvement ratio: -0.000569\n",
      "Feature L2-norm: 74.094606\n",
      "Learning rate (eta): 0.006240\n",
      "Total number of feature updates: 1798764\n",
      "Seconds required for this iteration: 2.224\n",
      "\n",
      "SGD terminated with the stopping criteria\n",
      "Loss: 4317.636528\n",
      "Total seconds required for training: 311.247\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 27502 (27502)\n",
      "Number of active attributes: 8385 (8385)\n",
      "Number of active labels: 7 (7)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from estnltk import estner\n",
    "from estnltk.corpus import read_json_corpus \n",
    "from estnltk.ner import NerTrainer\n",
    "# Read the default training corpus\n",
    "corpus = read_json_corpus('../../../estnltk/corpora/estner.json')\n",
    "\n",
    "\n",
    "# Read the default settings\n",
    "ner_settings = estner.settings\n",
    "\n",
    "# Directory to save the model\n",
    "model_dir = 'output_model_directory'\n",
    "\n",
    "# Train and save the model\n",
    "trainer = NerTrainer(ner_settings)\n",
    "trainer.train(corpus, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specified output directory will contain a resulting model file\n",
    "model.bin and a copy of a settings module used for training. Now we can\n",
    "load the model and tag some text using **NerTagger**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Eesti', 'B-ORG'),\n",
      " ('koeraspordiliidu', 'I-ORG'),\n",
      " ('(', 'O'),\n",
      " ('EKL', 'B-ORG'),\n",
      " (')', 'O'),\n",
      " ('presidendi', 'O'),\n",
      " ('Piret', 'B-PER'),\n",
      " ('Laanetu', 'I-PER'),\n",
      " ('intervjuu', 'O'),\n",
      " ('Eesti', 'B-ORG'),\n",
      " ('Päevalehele', 'I-ORG'),\n",
      " ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "from estnltk.ner import NerTagger\n",
    "\n",
    "document = Text('Eesti koeraspordiliidu ( EKL ) presidendi Piret Laanetu intervjuu Eesti Päevalehele.')\n",
    "\n",
    "# Load the model and settings\n",
    "tagger = NerTagger(model_dir)\n",
    "\n",
    "# ne-tag the document\n",
    "tagger.tag_document(document)\n",
    "\n",
    "pprint(list(zip(document.word_texts, document.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset\n",
    "\n",
    "To train a model with estnltk, you need to provide your training data in\n",
    "a certain format (see the default dataset\n",
    "estnltk/estnltk/corpora/estner.json for example). The training file\n",
    "contains one document per line along with ne-labels. Let's create a\n",
    "simple document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paragraphs': [{'end': 38, 'start': 0}],\n",
      " 'sentences': [{'end': 38, 'start': 0}],\n",
      " 'text': 'Eesti Vabariik on riik Põhja-Euroopas.',\n",
      " 'words': [{'end': 5, 'start': 0, 'text': 'Eesti'},\n",
      "           {'end': 14, 'start': 6, 'text': 'Vabariik'},\n",
      "           {'end': 17, 'start': 15, 'text': 'on'},\n",
      "           {'end': 22, 'start': 18, 'text': 'riik'},\n",
      "           {'end': 37, 'start': 23, 'text': 'Põhja-Euroopas'},\n",
      "           {'end': 38, 'start': 37, 'text': '.'}]}\n"
     ]
    }
   ],
   "source": [
    "text = Text('''Eesti Vabariik on riik Põhja-Euroopas.''')\n",
    "text.tokenize_words()\n",
    "pprint(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's add named entity tags to each word in the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': 5, 'label': 'B-LOC', 'start': 0, 'text': 'Eesti'},\n",
      " {'end': 14, 'label': 'I-LOC', 'start': 6, 'text': 'Vabariik'},\n",
      " {'end': 17, 'label': 'O', 'start': 15, 'text': 'on'},\n",
      " {'end': 22, 'label': 'O', 'start': 18, 'text': 'riik'},\n",
      " {'end': 37, 'label': 'B-LOC', 'start': 23, 'text': 'Põhja-Euroopas'},\n",
      " {'end': 38, 'label': 'O', 'start': 37, 'text': '.'}]\n"
     ]
    }
   ],
   "source": [
    "words = text.words\n",
    "\n",
    "# label each word as \"other\":\n",
    "for word in words:\n",
    "    word['label'] = 'O'\n",
    "\n",
    "# label words \"Eesti Vabariik\" as a location\n",
    "words[0]['label'] = 'B-LOC'\n",
    "words[1]['label'] = 'I-LOC'\n",
    "\n",
    "# label word \"Põhja-Euroopas\" as a location\n",
    "words[4]['label'] = 'B-LOC'\n",
    "\n",
    "pprint(text.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a collection of labelled documents, we can save it to disc\n",
    "using the function **write\\_json\\_corpus()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paragraphs': [{'end': 38, 'start': 0}],\n",
       "  'sentences': [{'end': 38, 'start': 0}],\n",
       "  'text': 'Eesti Vabariik on riik Põhja-Euroopas.',\n",
       "  'words': [{'end': 5, 'label': 'B-LOC', 'start': 0, 'text': 'Eesti'},\n",
       "   {'end': 14, 'label': 'I-LOC', 'start': 6, 'text': 'Vabariik'},\n",
       "   {'end': 17, 'label': 'O', 'start': 15, 'text': 'on'},\n",
       "   {'end': 22, 'label': 'O', 'start': 18, 'text': 'riik'},\n",
       "   {'end': 37, 'label': 'B-LOC', 'start': 23, 'text': 'Põhja-Euroopas'},\n",
       "   {'end': 38, 'label': 'O', 'start': 37, 'text': '.'}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.corpus import write_json_corpus\n",
    "\n",
    "documents = [text]\n",
    "write_json_corpus(documents, 'output_file_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This serializes each document object into a json string and saves to the\n",
    "specified file line by line. The resulting training file can be used\n",
    "with the **NerTrainer** as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ner settings\n",
    "\n",
    "By default, estnltk uses configuration module **estnltk.estner.settings**. A\n",
    "settings module defines training algorithm parameters, entity\n",
    "categories, feature extractors and feature templates. The simplest way\n",
    "to create a custom configuration is to make a new settings module, e.g.\n",
    "*custom\\_settings.py*, import the default settings and override necessary\n",
    "parts. For example, a custom minimalistic configuration module could\n",
    "look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom_settings.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom_settings.py\n",
    "\n",
    "from estnltk.estner.settings import *\n",
    "\n",
    "# Override feature templates\n",
    "TEMPLATES = [\n",
    "    (('lem', 0),),\n",
    "]\n",
    "\n",
    "# Override feature extractors\n",
    "FEATURE_EXTRACTORS = (\n",
    "    \"estnltk.estner.featureextraction.MorphFeatureExtractor\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import custom_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ner_settings2 = custom_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the **NerTrainer** instance can be initialized using the\n",
    "custom\\_settings module (make sure *custom\\_settings.py* is on your python\n",
    "path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = NerTrainer(ner_settings2)  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
