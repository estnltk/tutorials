{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental NP chunking\n",
    "========================\n",
    "\n",
    "Estnltk includes an experimental noun phrase chunker, which can be used\n",
    "to detect non-overlapping noun phrases from the text.\n",
    "\n",
    "Basic usage\n",
    "-----------\n",
    "\n",
    "The class **NounPhraseChunker** provides method\n",
    "**analyze\\_text()**, which takes a\n",
    "**Text** object as an input, detects potential noun\n",
    "phrases, and stores in the layer `NOUN_CHUNKS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': 17, 'start': 0, 'text': 'Suur karvane kass'},\n",
      " {'end': 41, 'start': 25, 'text': 'punasel diivanil'},\n",
      " {'end': 53, 'start': 43, 'text': 'väike hiir'},\n",
      " {'end': 71, 'start': 65, 'text': 'temast'}]\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.np_chunker import NounPhraseChunker\n",
    "from estnltk.names import TEXT, NOUN_CHUNKS\n",
    "from pprint import pprint\n",
    "\n",
    "# initialise the chunker\n",
    "chunker = NounPhraseChunker()\n",
    "\n",
    "text = Text('Suur karvane kass nurrus punasel diivanil, väike hiir aga hiilis temast mööda.')\n",
    "# chunk the input text\n",
    "text = chunker.analyze_text( text )\n",
    "\n",
    "# output the results (found phrases)\n",
    "pprint( text[NOUN_CHUNKS] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the method\n",
    ":py\\~estnltk.np\\_chunker.NounPhraseChunker.analyze\\_text returns the\n",
    "input text. The keyword argument `return_type` can be used to change the\n",
    "type of data returned. If `return_type='labels'`, the method returns\n",
    "results of chunking in a BIO annotation scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suur  B\n",
      "karvane  I\n",
      "kass  I\n",
      "nurrus  O\n",
      "punasel  B\n",
      "diivanil  I\n",
      ",  O\n",
      "väike  B\n",
      "hiir  I\n",
      "aga  O\n",
      "hiilis  O\n",
      "temast  B\n",
      "mööda  O\n",
      ".  O\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.np_chunker import NounPhraseChunker\n",
    "from estnltk.names import TEXT\n",
    "\n",
    "# initialise the chunker\n",
    "chunker = NounPhraseChunker()\n",
    "\n",
    "text = Text('Suur karvane kass nurrus punasel diivanil, väike hiir aga hiilis temast mööda.')\n",
    "\n",
    "# chunk the input text, get the results in BIO annotation format\n",
    "np_labels = chunker.analyze_text( text, return_type='labels' )\n",
    "\n",
    "# output results of the chunking in BIO annotation format\n",
    "for word, np_label in zip(text.words, np_labels):\n",
    "    print( word[TEXT]+'  '+str(np_label) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the resulting list `np_labels` contains a label\n",
    "for each word in the input text, indicating word's position in phrase:\n",
    "`\"B\"` denotes that the word begins a phrase, `\"I\"` indicates that the\n",
    "word is inside a phrase, and `\"O\"` indicates that the word does not\n",
    "belong to any noun phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the input argument `return_type=\"strings\"` is passed to the method,\n",
    "the method returns only results of the chunking as a list of phrase\n",
    "strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.np_chunker import NounPhraseChunker\n",
    "\n",
    "# initialise the chunker\n",
    "chunker = NounPhraseChunker()\n",
    "\n",
    "text = Text('Autojuhi lapitekk pälvis linna koduleheküljel paljude kodanike tähelepanu.')\n",
    "# chunk the input text\n",
    "phrase_strings = chunker.analyze_text( text, return_type=\"strings\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example produces following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Autojuhi lapitekk', 'linna koduleheküljel', 'paljude kodanike tähelepanu']\n"
     ]
    }
   ],
   "source": [
    "print( phrase_strings )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `return_type=\"tokens\"` is set, the chunker returns a list of lists of\n",
    "tokens, where each token is given as a dictonary containing analyses of\n",
    "the word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Autojuhi autojuht\n",
      "lapitekk lapitekk\n",
      "\n",
      "linna linn\n",
      "koduleheküljel kodulehekülg\n",
      "\n",
      "paljude palju\n",
      "kodanike kodanik\n",
      "tähelepanu tähelepanu\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.np_chunker import NounPhraseChunker\n",
    "from estnltk.names import TEXT, ANALYSIS, LEMMA\n",
    "\n",
    "# initialise the chunker\n",
    "chunker = NounPhraseChunker()\n",
    "\n",
    "text = Text('Autojuhi lapitekk pälvis linna koduleheküljel paljude kodanike tähelepanu.')\n",
    "# chunk the input text\n",
    "phrases = chunker.analyze_text( text, return_type=\"tokens\" )\n",
    "# output phrases word by word\n",
    "for phrase in phrases:\n",
    "    print()\n",
    "    for token in phrase:\n",
    "        # output text and first lemma\n",
    "        print( token[TEXT], token[ANALYSIS][0][LEMMA] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, regardless the `return_type`, the layer `NOUN_CHUNKS` will\n",
    "always be added to the input Text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutting phrases\n",
    "---------------\n",
    "\n",
    "By default, the chunker does not allow tagging phrases longer than 3\n",
    "words, as the quality of tagging longer phrases is likely suboptimal,\n",
    "and the coverage of these phrases is also likely low [[1]](#ref) . So, phrases\n",
    "longer than 3 words will be cut into one word phrases. This default\n",
    "setting can be turned off by specifying `cutPhrases=False` as an input\n",
    "argument for the method **analyze\\_text()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.np_chunker import NounPhraseChunker\n",
    "\n",
    "# initialise the chunker\n",
    "chunker = NounPhraseChunker()\n",
    "\n",
    "text = Text('Kõige väiksemate tassidega serviis toodi kusagilt vanast tolmusest kapist välja.')\n",
    "\n",
    "# chunk the input text while allowing phrases longer than 3 words\n",
    "phrase_strings = chunker.analyze_text( text, cutPhrases=False, return_type=\"strings\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kõige väiksemate tassidega serviis', 'vanast tolmusest kapist']\n"
     ]
    }
   ],
   "source": [
    "print( phrase_strings )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a custom syntactic parser\n",
    "-------------------------------\n",
    "\n",
    "By default, the MaltParser is used for obtaining the syntactic\n",
    "annotation, which is used as a basis in the chunking. Using the keyword\n",
    "argument `parser` in the initialization of the\n",
    "**NounPhraseChunker**, you can specify a custom\n",
    "parser to be used during the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': 5, 'start': 0, 'text': 'Maril'},\n",
      " {'end': 20, 'start': 10, 'text': 'väike tall'}]\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.np_chunker import NounPhraseChunker\n",
    "from estnltk.syntax.parsers import VISLCG3Parser\n",
    "\n",
    "# initialise the chunker using VISLCG3Parser instead of MaltParser\n",
    "chunker = NounPhraseChunker( parser = VISLCG3Parser() )\n",
    "\n",
    "text = Text('Maril oli väike tall.')\n",
    "# chunk the input text\n",
    "text = chunker.analyze_text( text )\n",
    "\n",
    "# output the results (found phrases)\n",
    "pprint( text[NOUN_CHUNKS] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "**References**\n",
    "\n",
    "[1]: An automatic analysis of the Balanced Corpus of Estonian suggests\n",
    "    that only 3% of all NP chunks are longer than 3 words."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
